{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "We will learn Pandas through the following tutorial:\n",
    "\n",
    "https://www.youtube.com/watch?v=5JnMutdy6Fw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notes\n",
    "\n",
    "* Press escape, and then press the letter __H__. It will bring up the help box showing all the keyboard shortcuts.\n",
    "* CTRL + A ... lets you highlight a whole codeblock, which is helpful for cutting/ deleting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Notes\n",
    "\n",
    "__//__ - this operator is like division, but the second slash 'chops off' the remainder in the division, leaving an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "2\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(5 / 2)\n",
    "print(5 // 2)\n",
    "print(type(5 // 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Notes\n",
    "\n",
    "Running the name of the dataframe will print out a large head and tail of the dataframe.\n",
    "\n",
    "__.tail()__ and __.head()__ actually __builds a new dataframe__. Therefore, you can use these operators to snip off the most interesting first few or last few entries in a dataframe. You can parse in a number which returns the last/ top values in the tail/head.\n",
    "\n",
    "## Filtering\n",
    "\n",
    "Filtering lets you __reduce__ a dataframe to only the rows that __match some criterion__. \n",
    "\n",
    "The columns in a dataframe are called \"__series__\". When these series are in the dataframe, they're called columns. Therefore, when you pull a column out of a dataframe, you have a series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['year'] # returns a series of just the year column\n",
    "df.year # exactly the same as the above line of code, both can be used interchangeably\n",
    "\n",
    "df.year > 1995 # returns a list filled with Trues and Falses\n",
    "df[df.year > 1995] # returns a dataframe that contains only the True values, FILTERS the False values\n",
    "\n",
    "df[(df.year < 1980) & (df.year >= 1990)] # returns a dataframe of years between the 90s and 80s. \n",
    "# Use the & instead of and, and | instead of or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".value_counts() # returns how many times each value appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".value_counts().head() # returns the most frequent values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to find a string that starts with a specific string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.str.startswith('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Indexes organize your data, and provide you fast access to it. \n",
    "\n",
    "Indexes only really helps Pandas out if they're __ordered__, however it speeds computation hundreds of times faster.\n",
    "\n",
    "Indexes can have __multiple columns__.\n",
    "\n",
    "Interestingly, the top of the dataframe (the 'titles' of the columns) are actually also indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ".set_index('new_index') # lets you change your index \n",
    ".set_index('new_index', append=True) # lets you add a new index to your existing indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".reset_index('old_index') # removes an index and transforms it back into a column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".reset_index(['index_a', 'index_b']) # transforms two indices back into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".unstack() # similar to set_index, but lets you move (starts with the letter U, therefore moves up) to the right\n",
    "           # tackles the innermost index by default\n",
    "           # moves indexes from the left, to become indexes on top\n",
    "           # this operation is supposedly awesome\n",
    "            # lets you get data that is vertically far apart, and set them right next to each other, by pivoting\n",
    "            # index information 'upstairs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".stack() # moves data back down (to the left index)\n",
    "         # note, that you can get a series either by stacking too much, or unstacking too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".loc[] # lets you specify a key for the index, like a python dictionary, and returns the values at that key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".groupby(['column_a', 'column_b', 'column_c']).size() # groups the three columns by their size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".fillna() # lets you specify what the NaN datatypes should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".fillna(method='ffill') # fills the NaNs by doing a forward fill\n",
    "                        # fills the NaNs with the last value that appeared before it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".fillna(method='bfill') # does a backward fill (opposite of forward fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".dt # datetime operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt.year # gets the year of a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt.dayofweek # gets the day of the week (monday, friday, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "By default automatically figures out which column names match, and merges two dataframes together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.merge(df2) # merges dataframe 1 with dataframe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".join() # similar to merge, but with different preset defaults. merge is more general, and hence better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot\n",
    "\n",
    "This performs a set index, a sort index, and an unstack operation, all in one go. Data scientists are always wanting to do those three operations all in a row, that there is this special .pivot() operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".pivot() # set index, sort index, unstack - all in one go. \n",
    "         # it takes 3 parameters, which it will set, sort and unstack respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".str.extract(r'\\((.*))\\') # r denotes a real expression\n",
    "                          # this returns anything inside a real parenthesis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
